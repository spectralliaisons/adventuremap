{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "import getexifdata, glob, os, json, io, shutil, logprogress\n",
    "\n",
    "DIR_PLACES = \"../Places/\"\n",
    "DIR_KML = \"kml/\"\n",
    "DIR_AUD = \"aud/\"\n",
    "DIR_IMG_ORIG = \"img/\"\n",
    "DIR_IMG_THUMBNAIL = \"imgSm/\"\n",
    "DIR_IMG_ERR = \"imgErr/\"\n",
    "\n",
    "IMG_FORMAT = \".jpg\"\n",
    "AUD_FORMAT = \".mp3\"\n",
    "\n",
    "INPUT_JSON = \"info_template.json\"\n",
    "OUTPUT_JSON = \"info.json\"\n",
    "SMRY_JSON = \"all_rivers.json\"\n",
    "\n",
    "SIZE_IMG_THUMBNAIL = 400\n",
    "\n",
    "# likely prefixes for original images named by the os when pic taken\n",
    "BLACKLIST_FLABEL_PREFIX = [\"IMG\", \"MVIMG\", \"PANO\"]\n",
    "\n",
    "# process every dir in Places/\n",
    "placels = glob.glob(DIR_PLACES + \"*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing place: ../Places/SF_Watershed/\n",
      "processing place: ../Places/Sacramento_River/\n",
      "processing place: ../Places/San_Joaquin_River/\n",
      "processing place: ../Places/Feather_River/\n",
      "processing place: ../Places/Russian_River/\n",
      "processing place: ../Places/Yuba_River/\n",
      "processing place: ../Places/Costa_Rica/\n",
      "processing place: ../Places/Eel_River/\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# or maybe only process a single place\n",
    "# placels = [DIR_PLACES + \"YubaRiver/\"]\n",
    "\n",
    "# create json of all places. initialize with a \"place\" called \"All\"\n",
    "all_places = {\"places\":[{\"id\":\"All\", \"disp\":\"All\"}]}\n",
    "\n",
    "# process each directory\n",
    "for base_path in logprogress.log_progress(placels):\n",
    "    \n",
    "    print(\"processing place: \" + base_path)\n",
    "    \n",
    "    # clear workspace\n",
    "    try:\n",
    "        shutil.rmtree(base_path + DIR_IMG_THUMBNAIL)\n",
    "        os.makedirs(base_path + DIR_IMG_THUMBNAIL)\n",
    "        shutil.rmtree(base_path + DIR_IMG_ERR)\n",
    "        os.makedirs(base_path + DIR_IMG_ERR)\n",
    "    except FileNotFoundError:\n",
    "        print(\"missing img dirs for: \" + base_path)\n",
    "\n",
    "    ####################\n",
    "    ###\n",
    "    ### helper functions\n",
    "    ###\n",
    "    \n",
    "    def strip_dir(fpath, dir):\n",
    "        i = fpath.index(dir)+len(dir)\n",
    "        return fpath[i:len(fpath)]\n",
    "\n",
    "    def get_fname(fpath):\n",
    "        return fpath.split(\"/\")[-1]\n",
    "\n",
    "    def get_flabel(fpath, ext):\n",
    "        return get_fname(fpath).replace(ext, \"\")\n",
    "\n",
    "    def find_audio_for_img(label):\n",
    "        for fpath in glob.glob(base_path + DIR_AUD + \"*\" + AUD_FORMAT):\n",
    "            flabel = get_flabel(fpath, AUD_FORMAT)\n",
    "            if flabel == label:\n",
    "                return strip_dir(fpath, \"/\" + DIR_AUD)\n",
    "        return None # no warning needed\n",
    "    \n",
    "    def save_err_img(fpath, msg):\n",
    "#         print(msg + \" : \" + fpath)\n",
    "        im = Image.open(fpath)\n",
    "        im.save(base_path + DIR_IMG_ERR + get_fname(fpath).replace(IMG_FORMAT, \"\") + \"_\" + msg + IMG_FORMAT)\n",
    "    \n",
    "    def get_gps_for_fpath(fpath):\n",
    "        im = Image.open(fpath)\n",
    "        edat = getexifdata.get_exif_data(im)\n",
    "        lat, lng = getexifdata.get_lat_lon(edat)\n",
    "        if lat == None or lng == None:\n",
    "            save_err_img(fpath, \"WARNING! no gps data for image\")\n",
    "            return None\n",
    "        else:\n",
    "            return {\"lat\":lat, \"lng\":lng}\n",
    "    \n",
    "    def get_date_for_fpath(fpath):\n",
    "        im = Image.open(fpath)\n",
    "        edat = getexifdata.get_exif_data(im)\n",
    "        date = edat[\"DateTime\"]\n",
    "        return date\n",
    "\n",
    "    try:\n",
    "        to_unicode = unicode\n",
    "    except NameError:\n",
    "        to_unicode = str    \n",
    "    \n",
    "    def find_kml():\n",
    "        return [strip_dir(fpath, \"/\" + DIR_KML) for fpath in glob.glob(base_path + DIR_KML + \"*.kml\")]\n",
    "    \n",
    "    def reorient_img(fileName, height):\n",
    "        # thanks storm_to : http://stackoverflow.com/questions/4228530/pil-thumbnail-is-rotating-my-image \n",
    "        fpath = base_path + DIR_IMG_ORIG + fileName\n",
    "        image=Image.open(fpath)\n",
    "        exif_raw = image._getexif()\n",
    "        if (exif_raw):\n",
    "            for orientation in ExifTags.TAGS.keys() : \n",
    "                if ExifTags.TAGS[orientation]=='Orientation' : break \n",
    "            exif=dict(exif_raw.items())\n",
    "            \n",
    "            try:\n",
    "                if   exif[orientation] == 3 : \n",
    "                    image=image.rotate(180, expand=True)\n",
    "                elif exif[orientation] == 6 : \n",
    "                    image=image.rotate(270, expand=True)\n",
    "                elif exif[orientation] == 8 : \n",
    "                    image=image.rotate(90, expand=True)\n",
    "            except KeyError:\n",
    "                False\n",
    "                #print(\"No orientation EXIF data for: \" + fileName)\n",
    "        \n",
    "        # thumnail\n",
    "        r = float(height) / image.size[1]\n",
    "        w = float(image.size[0]) * r\n",
    "        image.thumbnail((w, height), Image.ANTIALIAS)\n",
    "        image.save(base_path + DIR_IMG_THUMBNAIL + fileName)\n",
    "\n",
    "    ####################\n",
    "    ###\n",
    "    ### sanity check\n",
    "    ###\n",
    "\n",
    "    # sanity check: every audio file should have a matching img\n",
    "    def ensure_audio_img_match():\n",
    "        # error if an audio file has no image. slow, but we should ensure this.\n",
    "        for fpath in glob.glob(base_path + DIR_AUD + \"*\" + AUD_FORMAT):\n",
    "            match = False\n",
    "            for imgpath in glob.glob(base_path + DIR_IMG_ORIG + \"*\" + IMG_FORMAT):\n",
    "                if get_flabel(imgpath, IMG_FORMAT) == get_flabel(fpath, AUD_FORMAT):\n",
    "                    match = True\n",
    "            if not match:\n",
    "                #raise FileNotFoundError(\"no image for audio file: \" + fpath)\n",
    "                return True\n",
    "\n",
    "    # sanity check: every image should have GPS coordinates\n",
    "    def ensure_img_gps():\n",
    "        [get_gps_for_fpath(fpath) for fpath in glob.glob(base_path + DIR_IMG_ORIG + \"*\" + IMG_FORMAT)]\n",
    "    \n",
    "    # only permit location labels that were most likely hand-named image filenames\n",
    "    def verify_flabel(flabel):\n",
    "        # invalid label if filename begins with '201' (likely a date)\n",
    "        try:\n",
    "            flabel.index(\"201\")\n",
    "            return False\n",
    "        except ValueError:\n",
    "            False # ignore\n",
    "        # invalid label if blacklisted\n",
    "        for prefix in BLACKLIST_FLABEL_PREFIX:\n",
    "            try:\n",
    "                flabel.index(prefix)\n",
    "                return False\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return True\n",
    "\n",
    "    ####################\n",
    "    ###\n",
    "    ### run\n",
    "    ###\n",
    "    ensure_img_gps()\n",
    "    ensure_audio_img_match()\n",
    "\n",
    "    # read json template\n",
    "    with open(base_path + INPUT_JSON) as data_file:\n",
    "        data = json.load(data_file)\n",
    "        data[\"layers\"] = find_kml()\n",
    "\n",
    "        # for every image...\n",
    "        files = glob.glob(base_path + DIR_IMG_ORIG + \"*\" + IMG_FORMAT)\n",
    "        for fpath in logprogress.log_progress(files):\n",
    "            \n",
    "            # compile location info\n",
    "            flabel = get_flabel(fpath, IMG_FORMAT)\n",
    "            fnam = get_fname(fpath)\n",
    "            \n",
    "            #print(\"processing: \" + fnam)\n",
    "            \n",
    "            loc = get_gps_for_fpath(fpath)\n",
    "            date = get_date_for_fpath(fpath)\n",
    "            \n",
    "            if loc != None:\n",
    "                marker = {\n",
    "                    \"date\": date,\n",
    "                    \"loc\": loc,\n",
    "                    \"img\": fnam,\n",
    "                    \"aud\": find_audio_for_img(flabel)\n",
    "                }\n",
    "                if verify_flabel(flabel):\n",
    "                    marker[\"label\"] = flabel\n",
    "                data[\"locations\"].append(marker)\n",
    "\n",
    "                # save web-friendly image (rotated & small)\n",
    "                reorient_img(fnam, SIZE_IMG_THUMBNAIL)\n",
    "        \n",
    "        # Write JSON file\n",
    "        # http://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file-in-python\n",
    "        with io.open(base_path + OUTPUT_JSON, 'w', encoding='utf8') as outfile:\n",
    "            str_ = json.dumps(data,\n",
    "                              indent=4, sort_keys=True,\n",
    "                              separators=(',', ':'), ensure_ascii=False)\n",
    "            outfile.write(to_unicode(str_))\n",
    "    \n",
    "    # add to summary json\n",
    "    dirName = base_path.split(\"/\")[-2]\n",
    "    dispName = dirName.replace(\"_\", \" \")\n",
    "    \n",
    "    all_places[\"places\"].append({\n",
    "        \"id\": dirName,\n",
    "        \"disp\": dispName\n",
    "    })\n",
    "\n",
    "# write summary json: all place names\n",
    "with io.open(DIR_PLACES + SMRY_JSON, 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(all_places,\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ':'), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(str_))\n",
    "            \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "01b10366abc646d0add5d4235ddd0a6d": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "0732ae9c3e8a4342b2674c7154b7ddd0": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "0b0948b1b33b4d5885cc2df051246cbd": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "100c4557f9a042c2bc664f0406842a32": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "130dffc4602543ab8a3fcbd263d972d2": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "1828d1303ce64619bab7cdfb6488e9fa": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "18defb555eab43718d7f3f15226b9822": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "25f4d4d734b04538923a66d0fbb82ca5": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "2e82ed8f512f4148a581b7491c62ea81": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "466e5e0f17e14c559efeab848c627c29": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "5ea4e778519a449bad48f10263ab327c": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "7a8b143ef6d74d5b918cee3b1ef43478": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "b59047e965674c8e80b6ce3acf62bd26": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "c4c279f906a347ada7d8ec5f9b4c8531": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "d7bbdd7ce56e49fd956d215a1973afc9": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "e56a194349d94522911186689109fe2f": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "ec223761967548b5a66655598e7f32db": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
