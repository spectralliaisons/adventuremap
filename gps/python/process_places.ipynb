{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "from wand.image import Image as WandImage\n",
    "import getexifdata, glob, os, json, io, shutil, logprogress, numpy\n",
    "\n",
    "DIR_PLACES = \"../s3/\"\n",
    "DIR_PREFIX_IGNORE = DIR_PLACES + \"_\"\n",
    "DIR_GEODAT = \"geojson/\"\n",
    "DIR_AUD = \"aud/\"\n",
    "DIR_IMG_ORIG = \"imgOrig/\"\n",
    "DIR_IMG_LG = \"imgLg/\"\n",
    "DIR_IMG_THUMBNAIL = \"imgSm/\"\n",
    "DIR_IMG_ERR = \"imgErr/\"\n",
    "\n",
    "IMG_FORMAT = \".jpg\"\n",
    "AUD_FORMAT = \".mp3\"\n",
    "\n",
    "INPUT_JSON = \"info_template.json\"\n",
    "OUTPUT_JSON = \"info.json\"\n",
    "SMRY_JSON = \"all_rivers.json\"\n",
    "\n",
    "SIZE_IMG_THUMBNAIL = 400\n",
    "\n",
    "# likely prefixes for original images named by the os when pic taken\n",
    "BLACKLIST_FLABEL_PREFIX = [\"IMG\", \"MVIMG\", \"PANO\"]\n",
    "\n",
    "####################\n",
    "###\n",
    "### helper functions\n",
    "###\n",
    "\n",
    "def valid_place(path):\n",
    "    return not path.startswith(DIR_PREFIX_IGNORE)\n",
    "\n",
    "# if dir exists, clear it\n",
    "def init_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "def strip_dir(fpath, dir):\n",
    "    i = fpath.index(dir)+len(dir)\n",
    "    return fpath[i:len(fpath)]\n",
    "\n",
    "def get_fname(fpath):\n",
    "    return fpath.split(\"/\")[-1]\n",
    "\n",
    "def get_flabel(fpath, ext):\n",
    "    return get_fname(fpath).replace(ext, \"\")\n",
    "\n",
    "def find_audio_for_img(label):\n",
    "    for fpath in glob.glob(base_path + DIR_AUD + \"*\" + AUD_FORMAT):\n",
    "        flabel = get_flabel(fpath, AUD_FORMAT)\n",
    "        if flabel == label:\n",
    "            return strip_dir(fpath, \"/\" + DIR_AUD)\n",
    "    return None # no warning needed\n",
    "\n",
    "def for_img_with_exif(fpath, fnExif, fnNoExif):\n",
    "    im = get_im(fpath)\n",
    "    edat = getexifdata.get_exif_data(im)\n",
    "    lat, lng = getexifdata.get_lat_lon(edat)\n",
    "    if lat == None or lng == None:\n",
    "        if fnNoExif != None:\n",
    "            fnNoExif(fpath, im)\n",
    "        return None\n",
    "    else:\n",
    "        if fnExif != None:\n",
    "            fnExif(fpath, im)\n",
    "        return {\"lat\":lat, \"lng\":lng}\n",
    "\n",
    "def get_im(fpath):\n",
    "    try:\n",
    "        return Image.open(fpath)\n",
    "    except:\n",
    "        return as_pil_image(fpath)\n",
    "\n",
    "# convert HEIF images to PIL format\n",
    "def as_pil_image(fpath):\n",
    "    wand_im = WandImage(filename=fpath)\n",
    "    img_buffer = numpy.asarray(bytearray(wand_im.make_blob(format='png')), dtype='uint8')\n",
    "    bytesio = io.BytesIO(img_buffer)\n",
    "    return Image.open(bytesio)\n",
    "\n",
    "def get_gps_for_fpath(fpath):\n",
    "    return for_img_with_exif(fpath, None, None)\n",
    "\n",
    "def get_date_for_fpath(fpath):\n",
    "    im = Image.open(fpath)\n",
    "    edat = getexifdata.get_exif_data(im)\n",
    "    if \"DateTime\" in edat:\n",
    "        date = edat[\"DateTime\"]\n",
    "    elif \"DateTimeOriginal\" in edat:\n",
    "        date = edat[\"DateTimeOriginal\"]\n",
    "    else:\n",
    "        date = \"(Date Unknown)\"\n",
    "    return date\n",
    "\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str    \n",
    "\n",
    "def find_geodat():\n",
    "    return [strip_dir(fpath, \"/\" + DIR_GEODAT) for fpath in glob.glob(base_path + DIR_GEODAT + \"*.geojson\")]\n",
    "\n",
    "def reorient_img(fileName, height):\n",
    "    # thanks storm_to : http://stackoverflow.com/questions/4228530/pil-thumbnail-is-rotating-my-image \n",
    "    fpath = base_path + DIR_IMG_LG + fileName\n",
    "    image=Image.open(fpath)\n",
    "    exif_raw = image._getexif()\n",
    "    if (exif_raw):\n",
    "        for orientation in ExifTags.TAGS.keys() : \n",
    "            if ExifTags.TAGS[orientation]=='Orientation' : break \n",
    "        exif=dict(exif_raw.items())\n",
    "\n",
    "        try:\n",
    "            if   exif[orientation] == 3 : \n",
    "                image=image.rotate(180, expand=True)\n",
    "            elif exif[orientation] == 6 : \n",
    "                image=image.rotate(270, expand=True)\n",
    "            elif exif[orientation] == 8 : \n",
    "                image=image.rotate(90, expand=True)\n",
    "        except KeyError:\n",
    "            False\n",
    "            #print(\"No orientation EXIF data for: \" + fileName)\n",
    "\n",
    "    # thumnail\n",
    "    r = float(height) / image.size[1]\n",
    "    w = float(image.size[0]) * r\n",
    "    image.thumbnail((w, height), Image.ANTIALIAS)\n",
    "    image.save(base_path + DIR_IMG_THUMBNAIL + fileName)\n",
    "\n",
    "####################\n",
    "###\n",
    "### sanity check\n",
    "###\n",
    "\n",
    "# sanity check: every audio file should have a matching img\n",
    "def ensure_audio_img_match():\n",
    "    # error if an audio file has no image. slow, but we should ensure this.\n",
    "    for fpath in glob.glob(base_path + DIR_AUD + \"*\" + AUD_FORMAT):\n",
    "        match = False\n",
    "        for imgpath in glob.glob(base_path + DIR_IMG_LG + \"*\" + IMG_FORMAT):\n",
    "            if get_flabel(imgpath, IMG_FORMAT) == get_flabel(fpath, AUD_FORMAT):\n",
    "                match = True\n",
    "        if not match:\n",
    "            #raise FileNotFoundError(\"no image for audio file: \" + fpath)\n",
    "            return True\n",
    "\n",
    "# ensure each final image file is the desired extension & has GPS info\n",
    "def ensure_all_img_sanity():\n",
    "    [ensure_img_sanity(fpath) for fpath in glob.glob(base_path + DIR_IMG_ORIG + \"*\")]\n",
    "\n",
    "def ensure_img_sanity(fpath):\n",
    "    print(\"ensure_img_sanity\", fpath)\n",
    "    def fnExif(fpath, im):\n",
    "        extension = \".\" + fpath.split(\".\")[-1]\n",
    "        im.save(base_path + DIR_IMG_LG + get_fname(fpath).replace(extension, IMG_FORMAT), exif=im.info[\"exif\"])\n",
    "    def fnNoExif(fpath, im):\n",
    "        im.save(base_path + DIR_IMG_ERR + get_fname(fpath).replace(IMG_FORMAT, \"\") + \"_WARNING! no gps data for image\" + IMG_FORMAT)\n",
    "    for_img_with_exif(fpath, fnExif, fnNoExif)\n",
    "    \n",
    "# only permit location labels that were most likely hand-named image filenames\n",
    "def verify_flabel(flabel):\n",
    "    # invalid label if filename begins with '201' (likely a date)\n",
    "    try:\n",
    "        flabel.index(\"201\")\n",
    "        return False\n",
    "    except ValueError:\n",
    "        False # ignore\n",
    "    # invalid label if blacklisted\n",
    "    for prefix in BLACKLIST_FLABEL_PREFIX:\n",
    "        try:\n",
    "            flabel.index(prefix)\n",
    "            return False\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing place: ../s3/Yuba_River/\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_101857.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_4474.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_4475.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_130940.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_123201.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180114_121922.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_7219.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_122534.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_101110.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_122722.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_130953.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180115_091425.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_092133.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_093416.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180114_123329.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180115_091256.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/PANO_20180114_123132.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_190415.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_7250.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_7244.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_7249.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_190156.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_4433.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_4397.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180113_162453.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180113_165506.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_4482.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/MVIMG_20180113_152722.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_132150.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_184426.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_190309.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180114_093024.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_7211.jpg\n",
      "ensure_img_sanity ../s3/Yuba_River/imgOrig/IMG_20180902_130145.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd557023da04896ae09485896696d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=32)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "# process every dir in Places/\n",
    "placels = [x for x in logprogress.log_progress(glob.glob(DIR_PLACES + \"*/\")) if valid_place(x)]\n",
    "# placels = ['../s3/Yuba_River/'] # or process one place\n",
    "all_places = {\"places\":[]}\n",
    "\n",
    "# process each directory\n",
    "for base_path in placels:\n",
    "\n",
    "    print(\"processing place: \" + base_path)\n",
    "    \n",
    "    # clear workspace\n",
    "    init_dir(base_path + DIR_IMG_LG)\n",
    "    init_dir(base_path + DIR_IMG_THUMBNAIL)\n",
    "    init_dir(base_path + DIR_IMG_ERR)\n",
    "    \n",
    "    ensure_all_img_sanity()\n",
    "    ensure_audio_img_match()\n",
    "\n",
    "    # read json template\n",
    "    with open(base_path + INPUT_JSON) as data_file:\n",
    "        data = json.load(data_file)\n",
    "        data[\"layers\"] = find_geodat()\n",
    "\n",
    "        # for everyimage...\n",
    "        files = glob.glob(base_path + DIR_IMG_LG + \"*\" + IMG_FORMAT)\n",
    "        for fpath in logprogress.log_progress(files):\n",
    "            \n",
    "            # compile location info\n",
    "            flabel = get_flabel(fpath, IMG_FORMAT)\n",
    "            loc = get_gps_for_fpath(fpath)\n",
    "            \n",
    "            if loc != None:\n",
    "                fnam = get_fname(fpath)\n",
    "                date = get_date_for_fpath(fpath)\n",
    "                \n",
    "                marker = {\n",
    "                    \"date\": date,\n",
    "                    \"loc\": loc,\n",
    "                    \"img\": fnam,\n",
    "                    \"aud\": find_audio_for_img(flabel)\n",
    "                }\n",
    "                \n",
    "                if verify_flabel(flabel):\n",
    "                    marker[\"label\"] = flabel\n",
    "                \n",
    "                data[\"locations\"].append(marker)\n",
    "\n",
    "                # save web-friendly image (rotated & small)\n",
    "                reorient_img(fnam, SIZE_IMG_THUMBNAIL)\n",
    "        \n",
    "        # Write JSON file\n",
    "        # http://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file-in-python\n",
    "        with io.open(base_path + OUTPUT_JSON, 'w', encoding='utf8') as outfile:\n",
    "            str_ = json.dumps(data,\n",
    "                              indent=4, sort_keys=True,\n",
    "                              separators=(',', ':'), ensure_ascii=False)\n",
    "            outfile.write(to_unicode(str_))\n",
    "    \n",
    "    # add to summary json\n",
    "    dirName = base_path.split(\"/\")[-2]\n",
    "    dispName = dirName.replace(\"_\", \" \")\n",
    "    \n",
    "    all_places[\"places\"].append({\n",
    "        \"id\": dirName,\n",
    "        \"disp\": dispName\n",
    "    })\n",
    "\n",
    "# write summary json: all place names\n",
    "with io.open(DIR_PLACES + SMRY_JSON, 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(all_places,\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ':'), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(str_))\n",
    "            \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
