{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "from wand.image import Image as WandImage\n",
    "import getexifdata, glob, os, json, io, shutil, numpy, re, sys\n",
    "\n",
    "DIR_PLACES = \"../s3/\"\n",
    "DIR_PREFIX_IGNORE = DIR_PLACES + \"_\"\n",
    "IMG_PREFIX_NOMARKER = \"nomarker-\"\n",
    "DIR_GEODAT = \"geojson/\"\n",
    "DIR_AUD = \"aud/\"\n",
    "DIR_IMG_ORIG = \"imgOrig/\"\n",
    "DIR_IMG_LG = \"imgLg/\"\n",
    "DIR_IMG_THUMBNAIL = \"imgSm/\"\n",
    "DIR_IMG_ERR = \"imgErr/\"\n",
    "\n",
    "IMG_FORMAT = \".jpg\"\n",
    "AUD_FORMAT = \".mp3\"\n",
    "\n",
    "INPUT_JSON = \"info_template.json\"\n",
    "OUTPUT_JSON = \"info.json\"\n",
    "SMRY_JSON = \"all_rivers.json\"\n",
    "\n",
    "SIZE_IMG_THUMBNAIL = 400\n",
    "\n",
    "# likely prefixes for original images named by the os when pic taken\n",
    "BLACKLIST_FLABEL_PREFIX = [\"IMG\", \"MVIMG\", \"PANO\"]\n",
    "\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str\n",
    "\n",
    "def valid_place(path):\n",
    "    return not path.startswith(DIR_PREFIX_IGNORE)\n",
    "\n",
    "def dont_create_marker_for_fpath(fpath):\n",
    "    return get_fname(fpath).startswith(IMG_PREFIX_NOMARKER)\n",
    "\n",
    "# if dir exists, clear it\n",
    "def init_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "def strip_dir(fpath, dir):\n",
    "    i = fpath.index(dir)+len(dir)\n",
    "    return fpath[i:len(fpath)]\n",
    "\n",
    "def get_fname(fpath):\n",
    "    return fpath.split(\"/\")[-1]\n",
    "\n",
    "def get_flabel(fpath, ext):\n",
    "    return get_fname(fpath).replace(ext, \"\")\n",
    "\n",
    "def for_img_with_exif(fpath, fnExif, fnNoExif):\n",
    "    im = get_im(fpath)\n",
    "    edat = getexifdata.get_exif_data(im)\n",
    "    lat, lng = getexifdata.get_lat_lon(edat)\n",
    "    if lat == None or lng == None:\n",
    "        if fnNoExif != None:\n",
    "            fnNoExif(fpath, im)\n",
    "        return None\n",
    "    else:\n",
    "        if fnExif != None:\n",
    "            fnExif(fpath, im)\n",
    "        return {\"lat\":lat, \"lng\":lng}\n",
    "\n",
    "def get_im(fpath):\n",
    "    try:\n",
    "        return Image.open(fpath)\n",
    "    except:\n",
    "        return as_pil_image(fpath)\n",
    "\n",
    "# convert HEIF images to PIL format\n",
    "def as_pil_image(fpath):\n",
    "    wand_im = WandImage(filename=fpath)\n",
    "    img_buffer = numpy.asarray(bytearray(wand_im.make_blob(format='png')), dtype='uint8')\n",
    "    bytesio = io.BytesIO(img_buffer)\n",
    "    return Image.open(bytesio)\n",
    "\n",
    "def get_gps_for_fpath(fpath):\n",
    "    if dont_create_marker_for_fpath(fpath):\n",
    "        return None \n",
    "    else:\n",
    "        return for_img_with_exif(fpath, None, None)\n",
    "\n",
    "def get_date_for_fpath(fpath):\n",
    "    im = Image.open(fpath)\n",
    "    edat = getexifdata.get_exif_data(im)\n",
    "    if \"DateTime\" in edat:\n",
    "        date = edat[\"DateTime\"]\n",
    "    elif \"DateTimeOriginal\" in edat:\n",
    "        date = edat[\"DateTimeOriginal\"]\n",
    "    else:\n",
    "        date = \"(Date Unknown)\"\n",
    "    return date\n",
    "    \n",
    "# only permit location labels that were most likely hand-named image filenames\n",
    "def verify_flabel(flabel):\n",
    "    # invalid label if filename begins with '201' (likely a date)\n",
    "    try:\n",
    "        flabel.index(\"201\")\n",
    "        return False\n",
    "    except ValueError:\n",
    "        False # ignore\n",
    "    # invalid label if blacklisted\n",
    "    for prefix in BLACKLIST_FLABEL_PREFIX:\n",
    "        try:\n",
    "            flabel.index(prefix)\n",
    "            return False\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return True\n",
    "\n",
    "def find_audio_for_img(base_path, label):\n",
    "    for fpath in glob.glob(base_path + DIR_AUD + \"*\" + AUD_FORMAT):\n",
    "        flabel = get_flabel(fpath, AUD_FORMAT)\n",
    "        if flabel == label:\n",
    "            return strip_dir(fpath, \"/\" + DIR_AUD)\n",
    "    return None # no warning needed\n",
    "\n",
    "def find_geodat(base_path):\n",
    "    return [strip_dir(fpath, \"/\" + DIR_GEODAT) for fpath in glob.glob(base_path + DIR_GEODAT + \"*.geojson\")]\n",
    "\n",
    "def reorient_img(base_path, fileName, height):\n",
    "    # thanks storm_to : http://stackoverflow.com/questions/4228530/pil-thumbnail-is-rotating-my-image \n",
    "    fpath = base_path + DIR_IMG_LG + fileName\n",
    "    image=Image.open(fpath)\n",
    "    exif_raw = image._getexif()\n",
    "    if (exif_raw):\n",
    "        for orientation in ExifTags.TAGS.keys() : \n",
    "            if ExifTags.TAGS[orientation]=='Orientation' : break \n",
    "        exif=dict(exif_raw.items())\n",
    "\n",
    "        try:\n",
    "            if   exif[orientation] == 3 : \n",
    "                image=image.rotate(180, expand=True)\n",
    "            elif exif[orientation] == 6 : \n",
    "                image=image.rotate(270, expand=True)\n",
    "            elif exif[orientation] == 8 : \n",
    "                image=image.rotate(90, expand=True)\n",
    "        except KeyError:\n",
    "            False\n",
    "            #print(\"No orientation EXIF data for: \" + fileName)\n",
    "\n",
    "    # thumnail\n",
    "    r = float(height) / image.size[1]\n",
    "    w = float(image.size[0]) * r\n",
    "    image.thumbnail((w, height), Image.ANTIALIAS)\n",
    "    image.save(base_path + DIR_IMG_THUMBNAIL + fileName)\n",
    "\n",
    "# sanity check: every audio file should have a matching img\n",
    "def ensure_audio_img_match(base_path):\n",
    "    # error if an audio file has no image. slow, but we should ensure this.\n",
    "    for fpath in glob.glob(base_path + DIR_AUD + \"*\" + AUD_FORMAT):\n",
    "        match = False\n",
    "        for imgpath in glob.glob(base_path + DIR_IMG_LG + \"*\" + IMG_FORMAT):\n",
    "            if get_flabel(imgpath, IMG_FORMAT) == get_flabel(fpath, AUD_FORMAT):\n",
    "                match = True\n",
    "        if not match:\n",
    "            #raise FileNotFoundError(\"no image for audio file: \" + fpath)\n",
    "            return True\n",
    "\n",
    "# ensure each final image file is the desired extension & has GPS info\n",
    "def ensure_all_img_sanity(base_path):\n",
    "    [ensure_img_sanity(base_path, fpath) for fpath in glob.glob(base_path + DIR_IMG_ORIG + \"*\")]\n",
    "\n",
    "def ensure_img_sanity(base_path, fpath):\n",
    "    def saveLgImg(fpath, im):\n",
    "        extension = \".\" + fpath.split(\".\")[-1]\n",
    "        im.save(base_path + DIR_IMG_LG + get_fname(fpath).replace(extension, IMG_FORMAT), exif=im.info[\"exif\"])\n",
    "    def saveErrImg(fpath, im):\n",
    "        im.save(base_path + DIR_IMG_ERR + get_fname(fpath).replace(IMG_FORMAT, \"\") + \"_WARNING! no gps data for image\" + IMG_FORMAT)\n",
    "    if dont_create_marker_for_fpath(fpath):\n",
    "        saveLgImg(fpath, get_im(fpath))\n",
    "    else:\n",
    "        for_img_with_exif(fpath, saveLgImg, saveErrImg)\n",
    "\n",
    "# display progress on the same line\n",
    "def show_progress():\n",
    "    size = 0\n",
    "    def out(prefix, n):\n",
    "        nonlocal size\n",
    "        disp = f\"{prefix} {'[%d%%]' % n}\"\n",
    "        sys.stdout.write(\"\\r\" + \" \" * size + \"\\r\")\n",
    "        sys.stdout.write(disp)\n",
    "        sys.stdout.flush()\n",
    "        size = len(disp)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../s3/Eel_River/ [100%]        done.\n"
     ]
    }
   ],
   "source": [
    "# process every dir in Places/\n",
    "placels = [x for x in glob.glob(DIR_PLACES + \"*/\") if valid_place(x)]\n",
    "# placels = ['../s3/Sacramento_River/'] # or process one place\n",
    "all_places = {\"places\":[]}\n",
    "\n",
    "progress = show_progress()\n",
    "\n",
    "# process each directory\n",
    "for base_path in placels:\n",
    "    # clear workspace\n",
    "    init_dir(base_path + DIR_IMG_LG)\n",
    "    init_dir(base_path + DIR_IMG_THUMBNAIL)\n",
    "    init_dir(base_path + DIR_IMG_ERR)\n",
    "    \n",
    "    ensure_all_img_sanity(base_path)\n",
    "    ensure_audio_img_match(base_path)\n",
    "\n",
    "    # read json template\n",
    "    with open(base_path + INPUT_JSON) as data_file:\n",
    "        data = json.load(data_file)\n",
    "        data[\"layers\"] = find_geodat(base_path)\n",
    "\n",
    "        # for everyimage...\n",
    "        files = glob.glob(base_path + DIR_IMG_LG + \"*\" + IMG_FORMAT)\n",
    "        for i, fpath in enumerate(files):\n",
    "            \n",
    "            progress(base_path, (100*(i+1)/len(files)))\n",
    "            \n",
    "            fname = get_fname(fpath)\n",
    "            loc = get_gps_for_fpath(fpath)\n",
    "        \n",
    "            if loc != None:\n",
    "                flabel = get_flabel(fpath, IMG_FORMAT)\n",
    "                data[\"locations\"].append({\n",
    "                    \"loc\": loc,\n",
    "                    \"img\": fname,\n",
    "                    \"label\": flabel if verify_flabel(flabel) else None,\n",
    "                    \"date\": get_date_for_fpath(fpath),\n",
    "                    \"aud\": find_audio_for_img(base_path, flabel)\n",
    "                })\n",
    "\n",
    "            # save web-friendly image (rotated & small)\n",
    "            reorient_img(base_path, fname, SIZE_IMG_THUMBNAIL)\n",
    "        \n",
    "        # Write JSON file\n",
    "        # http://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file-in-python\n",
    "        with io.open(base_path + OUTPUT_JSON, 'w', encoding='utf8') as outfile:\n",
    "            str_ = json.dumps(data,\n",
    "                              indent=4, sort_keys=True,\n",
    "                              separators=(',', ':'), ensure_ascii=False)\n",
    "            outfile.write(to_unicode(str_))\n",
    "    \n",
    "    # add to summary json\n",
    "    dirName = base_path.split(\"/\")[-2]\n",
    "    \n",
    "    # displayed place replaces \"_\" with \" \" and wraps years (yyyy) in parentheses\n",
    "    dispName = re.sub(r\"\\d{4}\", r\"(\\g<0>)\", dirName.replace(\"_\", \" \"))\n",
    "    \n",
    "    all_places[\"places\"].append({\n",
    "        \"id\": dirName,\n",
    "        \"disp\": dispName,\n",
    "        \"local\": data.get(\"local\") or False # This flag tells the client to list this place only at localhost\n",
    "    })\n",
    "\n",
    "# write summary json: all place names\n",
    "with io.open(DIR_PLACES + SMRY_JSON, 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(all_places,\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ':'), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(str_))\n",
    "            \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
